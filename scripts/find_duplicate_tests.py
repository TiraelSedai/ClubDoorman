#!/usr/bin/env python3
"""
Duplicate Test Finder - –Ω–∞—Ö–æ–¥–∏—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –¥—É–±–ª–∏—Ä—É—é—â–∏–µ —Ç–µ—Å—Ç—ã
"""

import os
import re
import difflib
from collections import defaultdict
import json

def find_duplicate_tests(test_dir="ClubDoorman.Test"):
    """–ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –¥—É–±–ª–∏—Ä—É—é—â–∏–µ —Ç–µ—Å—Ç—ã"""
    print("üîç Scanning for duplicate tests...")
    
    test_methods = {}
    
    # –°–∫–∞–Ω–∏—Ä—É–µ–º –≤—Å–µ —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
    for root, dirs, files in os.walk(test_dir):
        for file in files:
            if file.endswith(".cs") and "Test" in file:
                filepath = os.path.join(root, file)
                analyze_test_file(filepath, test_methods)
    
    print(f"üìä Found {len(test_methods)} test methods")
    
    # –ò—â–µ–º –¥—É–±–ª–∏
    duplicates = find_similar_tests(test_methods)
    
    print(f"üîç Found {len(duplicates)} potential duplicates")
    return duplicates, test_methods

def analyze_test_file(filepath, test_methods):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã—Ö –º–µ—Ç–æ–¥–æ–≤"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"‚ùå Error reading {filepath}: {e}")
        return
        
    # –ò—â–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –º–µ—Ç–æ–¥—ã (–±–æ–ª–µ–µ –≥–∏–±–∫–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω)
    test_pattern = r'\[Test\][\s\S]*?public[\s\S]*?void\s+(\w+)\s*\([^)]*\)\s*\{([\s\S]*?)(?=\n\s*(?:\[Test\]|\[.*\]|public|private|protected|internal|\}|$))'
    matches = re.findall(test_pattern, content, re.MULTILINE)
    
    for method_name, method_body in matches:
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–ª–æ –º–µ—Ç–æ–¥–∞ (—É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏)
        normalized_body = normalize_method_body(method_body)
        
        test_methods[f"{filepath}::{method_name}"] = {
            'name': method_name,
            'body': normalized_body,
            'file': filepath,
            'original_body': method_body.strip()
        }

def normalize_method_body(body):
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–ª–æ –º–µ—Ç–æ–¥–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    # –£–±–∏—Ä–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
    body = re.sub(r'//.*', '', body)
    body = re.sub(r'/\*.*?\*/', '', body, flags=re.DOTALL)
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
    body = re.sub(r'\s+', ' ', body)
    
    # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –ª–∏—Ç–µ—Ä–∞–ª—ã (–º–æ–≥—É—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è)
    body = re.sub(r'"[^"]*"', '"STRING"', body)
    
    # –£–±–∏—Ä–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ª–∏—Ç–µ—Ä–∞–ª—ã
    body = re.sub(r'\b\d+\b', 'NUMBER', body)
    
    return body.strip()

def find_similar_tests(test_methods):
    """–ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ —Ç–µ—Å—Ç—ã"""
    duplicates = []
    methods = list(test_methods.items())
    
    print("üîç Comparing test methods for similarity...")
    
    for i in range(len(methods)):
        for j in range(i + 1, len(methods)):
            key1, method1 = methods[i]
            key2, method2 = methods[j]
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –∏–∑ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏–º–∏ –∏–º–µ–Ω–∞–º–∏
            if method1['file'] == method2['file'] and \
               difflib.SequenceMatcher(None, method1['name'], method2['name']).ratio() > 0.8:
                continue
            
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ç–µ–ª–∞ –º–µ—Ç–æ–¥–æ–≤
            similarity = difflib.SequenceMatcher(
                None, method1['body'], method2['body']
            ).ratio()
            
            if similarity > 0.75:  # 75% –ø–æ—Ö–æ–∂–µ—Å—Ç–∏
                duplicates.append({
                    'method1': key1,
                    'method2': key2,
                    'similarity': similarity,
                    'file1': method1['file'],
                    'file2': method2['file'],
                    'name1': method1['name'],
                    'name2': method2['name']
                })
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –ø–æ—Ö–æ–∂–µ—Å—Ç–∏
    duplicates.sort(key=lambda x: x['similarity'], reverse=True)
    
    return duplicates

def categorize_duplicates(duplicates):
    """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä—É–µ—Ç –¥—É–±–ª–∏ –ø–æ —Ç–∏–ø–∞–º"""
    categories = {
        'exact_duplicates': [],      # > 95% –ø–æ—Ö–æ–∂–µ—Å—Ç–∏
        'high_similarity': [],       # 90-95% –ø–æ—Ö–æ–∂–µ—Å—Ç–∏  
        'medium_similarity': [],     # 80-90% –ø–æ—Ö–æ–∂–µ—Å—Ç–∏
        'cross_file_duplicates': [], # –î—É–±–ª–∏ –º–µ–∂–¥—É —Ä–∞–∑–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏
        'same_file_variants': []     # –í–∞—Ä–∏–∞–Ω—Ç—ã –≤ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ
    }
    
    for dup in duplicates:
        similarity = dup['similarity']
        
        if similarity > 0.95:
            categories['exact_duplicates'].append(dup)
        elif similarity > 0.90:
            categories['high_similarity'].append(dup)
        elif similarity > 0.80:
            categories['medium_similarity'].append(dup)
            
        if dup['file1'] != dup['file2']:
            categories['cross_file_duplicates'].append(dup)
        else:
            categories['same_file_variants'].append(dup)
    
    return categories

def generate_report(duplicates, test_methods, output_file="duplicate_tests_report.md"):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –æ –¥—É–±–ª—è—Ö"""
    categories = categorize_duplicates(duplicates)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# üîç Duplicate Tests Analysis Report\n\n")
        f.write(f"**Generated:** {__import__('datetime').datetime.now()}\n\n")
        
        f.write("## üìä Summary\n\n")
        f.write(f"- **Total test methods:** {len(test_methods)}\n")
        f.write(f"- **Potential duplicates:** {len(duplicates)}\n")
        f.write(f"- **Exact duplicates (>95%):** {len(categories['exact_duplicates'])}\n")
        f.write(f"- **High similarity (90-95%):** {len(categories['high_similarity'])}\n")
        f.write(f"- **Cross-file duplicates:** {len(categories['cross_file_duplicates'])}\n\n")
        
        # Exact duplicates (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è)
        if categories['exact_duplicates']:
            f.write("## üö® Exact Duplicates (Priority for removal)\n\n")
            for dup in categories['exact_duplicates']:
                f.write(f"### {dup['similarity']:.1%} similarity\n")
                f.write(f"- **File 1:** `{dup['file1']}::{dup['name1']}`\n")
                f.write(f"- **File 2:** `{dup['file2']}::{dup['name2']}`\n")
                f.write(f"- **Recommendation:** Remove one of them\n\n")
        
        # Cross-file duplicates
        if categories['cross_file_duplicates']:
            f.write("## üîÑ Cross-File Duplicates\n\n")
            for dup in categories['cross_file_duplicates'][:10]:  # Top 10
                f.write(f"### {dup['similarity']:.1%} similarity\n")
                f.write(f"- **File 1:** `{dup['file1']}::{dup['name1']}`\n")
                f.write(f"- **File 2:** `{dup['file2']}::{dup['name2']}`\n\n")
        
        # High similarity
        if categories['high_similarity']:
            f.write("## ‚ö†Ô∏è High Similarity Tests\n\n")
            for dup in categories['high_similarity'][:10]:  # Top 10
                f.write(f"### {dup['similarity']:.1%} similarity\n")
                f.write(f"- **File 1:** `{dup['file1']}::{dup['name1']}`\n")
                f.write(f"- **File 2:** `{dup['file2']}::{dup['name2']}`\n\n")
    
    print(f"üìù Report generated: {output_file}")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üîç Duplicate Test Finder")
    print("=" * 50)
    
    duplicates, test_methods = find_duplicate_tests()
    
    if duplicates:
        print("\nüö® Top 10 most similar tests:")
        for i, dup in enumerate(duplicates[:10], 1):
            print(f"{i:2d}. {dup['similarity']:.1%} - {dup['name1']} <-> {dup['name2']}")
            print(f"    {dup['file1']}")
            print(f"    {dup['file2']}")
            print()
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    generate_report(duplicates, test_methods, "plans/current/test-reorganization/duplicate_tests_report.md")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    with open("plans/current/test-reorganization/duplicate_tests_data.json", 'w', encoding='utf-8') as f:
        json.dump({
            'duplicates': duplicates,
            'summary': {
                'total_methods': len(test_methods),
                'total_duplicates': len(duplicates),
                'exact_duplicates': len([d for d in duplicates if d['similarity'] > 0.95])
            }
        }, f, indent=2, ensure_ascii=False)
    
    print("‚úÖ Analysis complete!")

if __name__ == "__main__":
    main()