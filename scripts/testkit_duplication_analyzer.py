#!/usr/bin/env python3
"""
TestKit Duplication & Complexity Analyzer
ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ TestKit Ğ½Ğ° Ğ¿Ñ€ĞµĞ´Ğ¼ĞµÑ‚ Ğ¿ĞµÑ€ĞµÑƒÑĞ»Ğ¾Ğ¶Ğ½ĞµĞ½Ğ¸Ñ, Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
"""

import json
import re
from collections import defaultdict, Counter
from pathlib import Path
from typing import Dict, List, Set, Tuple
from dataclasses import dataclass

@dataclass
class DuplicationPattern:
    pattern: str
    methods: List[str]
    files: List[str] 
    severity: str  # "high", "medium", "low"
    optimization_potential: str

@dataclass
class ComplexityIssue:
    component: str
    issue_type: str
    description: str
    methods_count: int
    lines_count: int
    optimization_suggestion: str

class TestKitAnalyzer:
    def __init__(self, index_path: str):
        self.index_path = Path(index_path)
        self.index_data = None
        self.duplications: List[DuplicationPattern] = []
        self.complexity_issues: List[ComplexityIssue] = []
        
    def load_index(self):
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ JSON Ğ¸Ğ½Ğ´ĞµĞºÑ"""
        with open(self.index_path, 'r', encoding='utf-8') as f:
            self.index_data = json.load(f)
    
    def analyze_method_name_patterns(self):
        """ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ² Ğ¸Ğ¼ĞµĞ½Ğ°Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ"""
        method_patterns = defaultdict(list)
        
        for component in self.index_data['components']:
            for method in component['methods']:
                # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ¸Ğ· Ğ¸Ğ¼ĞµĞ½ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²
                base_patterns = self.extract_base_patterns(method['name'])
                for pattern in base_patterns:
                    method_patterns[pattern].append({
                        'method': method['name'],
                        'file': component['file_name'],
                        'return_type': method['return_type']
                    })
        
        # Ğ˜Ñ‰ĞµĞ¼ Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
        for pattern, methods in method_patterns.items():
            if len(methods) > 2:  # Ğ‘Ğ¾Ğ»ÑŒÑˆĞµ 2Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ñ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğ¸Ğ¼ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ¼
                severity = self.assess_duplication_severity(methods)
                if severity != "ignore":
                    self.duplications.append(DuplicationPattern(
                        pattern=pattern,
                        methods=[m['method'] for m in methods],
                        files=list(set(m['file'] for m in methods)),
                        severity=severity,
                        optimization_potential=self.suggest_optimization(pattern, methods)
                    ))
    
    def extract_base_patterns(self, method_name: str) -> List[str]:
        """Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ¸Ğ· Ğ¸Ğ¼ĞµĞ½Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°"""
        patterns = []
        
        # ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ²
        if method_name.startswith('Create'):
            # CreateValidUser, CreateBotUser -> Create*User
            if 'User' in method_name:
                patterns.append('Create*User')
            if 'Message' in method_name:
                patterns.append('Create*Message')
            if 'Chat' in method_name:
                patterns.append('Create*Chat')
            if 'Mock' in method_name:
                patterns.append('Create*Mock')
            if 'Service' in method_name:
                patterns.append('Create*Service')
            if 'Factory' in method_name:
                patterns.append('Create*Factory')
                
        # ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ±Ğ¸Ğ»Ğ´ĞµÑ€Ğ¾Ğ²
        if 'Builder' in method_name:
            patterns.append('*Builder')
            
        # ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
        if 'Result' in method_name:
            patterns.append('*Result')
            
        return patterns
    
    def assess_duplication_severity(self, methods: List[Dict]) -> str:
        """ĞÑ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚ ÑĞµÑ€ÑŒĞµĞ·Ğ½Ğ¾ÑÑ‚ÑŒ Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ"""
        # Ğ•ÑĞ»Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ² Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ°Ñ… - Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
        files = set(m['file'] for m in methods)
        if len(files) > 1:
            return "high"
        
        # Ğ•ÑĞ»Ğ¸ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ñ Ğ¾Ğ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ñ‹Ğ¼ Ñ‚Ğ¸Ğ¿Ğ¾Ğ¼ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ° - Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ¸
        return_types = set(m['return_type'] for m in methods)
        if len(return_types) == 1 and len(methods) > 3:
            return "medium"
            
        # Ğ•ÑĞ»Ğ¸ Ğ² Ğ¾Ğ´Ğ½Ğ¾Ğ¼ Ñ„Ğ°Ğ¹Ğ»Ğµ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğ¸Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² - Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿ĞµÑ€ĞµÑƒÑĞ»Ğ¾Ğ¶Ğ½ĞµĞ½Ğ¸Ğµ
        if len(files) == 1 and len(methods) > 5:
            return "medium"
            
        return "low"
    
    def suggest_optimization(self, pattern: str, methods: List[Dict]) -> str:
        """ĞŸÑ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ± Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸"""
        files = set(m['file'] for m in methods)
        
        if len(files) > 1:
            return f"Consolidate {len(methods)} methods from {len(files)} files into single location"
        
        if pattern == 'Create*User':
            return "Consider user builder with enum parameter: CreateUser(UserType.Valid|Bot|Anonymous)"
        elif pattern == 'Create*Message':
            return "Consider message builder with fluent API or message type enum"
        elif pattern == 'Create*Mock':
            return "Consider generic mock factory: CreateMock<T>() with configuration"
        elif pattern == '*Builder':
            return "Check if builders can share common base class or interface"
        else:
            return "Review for consolidation opportunity"
    
    def analyze_component_complexity(self):
        """ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²"""
        for component in self.index_data['components']:
            methods_count = len(component['methods'])
            lines_count = component['lines_count']
            
            # Ğ¤Ğ°Ğ¹Ğ»Ñ‹ Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾Ğ¼ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²
            if methods_count > 30:
                self.complexity_issues.append(ComplexityIssue(
                    component=component['file_name'],
                    issue_type="high_method_count",
                    description=f"Component has {methods_count} methods",
                    methods_count=methods_count,
                    lines_count=lines_count,
                    optimization_suggestion="Consider splitting into multiple specialized classes"
                ))
            
            # Ğ¤Ğ°Ğ¹Ğ»Ñ‹ Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾Ğ¼ ÑÑ‚Ñ€Ğ¾Ğº
            if lines_count > 500:
                self.complexity_issues.append(ComplexityIssue(
                    component=component['file_name'],
                    issue_type="high_line_count", 
                    description=f"Component has {lines_count} lines",
                    methods_count=methods_count,
                    lines_count=lines_count,
                    optimization_suggestion="Consider breaking into smaller modules"
                ))
            
            # ĞĞ¸Ğ·ĞºĞ°Ñ Ğ¿Ğ»Ğ¾Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² (Ğ¼Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ´Ğ° Ğ½Ğ° Ğ¼ĞµÑ‚Ğ¾Ğ´)
            if methods_count > 0:
                lines_per_method = lines_count / methods_count
                if lines_per_method > 20:
                    self.complexity_issues.append(ComplexityIssue(
                        component=component['file_name'],
                        issue_type="low_method_density",
                        description=f"Average {lines_per_method:.1f} lines per method",
                        methods_count=methods_count,
                        lines_count=lines_count,
                        optimization_suggestion="Methods might be too complex - consider simplification"
                    ))
    
    def analyze_tag_overlap(self):
        """ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿ĞµÑ€ĞµÑĞµÑ‡ĞµĞ½Ğ¸Ñ Ñ‚ĞµĞ³Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸"""
        tag_to_methods = defaultdict(list)
        
        for component in self.index_data['components']:
            for method in component['methods']:
                for tag in method['tags']:
                    tag_to_methods[tag].append({
                        'method': method['name'],
                        'file': component['file_name'],
                        'component': component['file_name']
                    })
        
        # Ğ˜Ñ‰ĞµĞ¼ Ñ‚ĞµĞ³Ğ¸ Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾Ğ¼ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ² Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ°Ñ…
        for tag, methods in tag_to_methods.items():
            files = set(m['file'] for m in methods)
            if len(files) > 3 and len(methods) > 10:  # ĞœĞ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ² Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ°Ñ…
                self.duplications.append(DuplicationPattern(
                    pattern=f"tag:{tag}",
                    methods=[m['method'] for m in methods[:10]],  # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 10
                    files=list(files),
                    severity="medium",
                    optimization_potential=f"Consider consolidating '{tag}' functionality"
                ))
    
    def generate_report(self):
        """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¾Ñ‚Ñ‡ĞµÑ‚ Ğ¾Ğ± Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğµ"""
        output_path = self.index_path.parent / "DUPLICATION_ANALYSIS.md"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("# TestKit Duplication & Complexity Analysis\n\n")
            f.write(f"**Generated:** {self.index_data['generated']}\n")
            f.write(f"**Total Components:** {len(self.index_data['components'])}\n")
            f.write(f"**Total Methods:** {sum(len(c['methods']) for c in self.index_data['components'])}\n\n")
            
            # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
            f.write("## ğŸ” Duplication Analysis\n\n")
            if self.duplications:
                high_duplications = [d for d in self.duplications if d.severity == "high"]
                medium_duplications = [d for d in self.duplications if d.severity == "medium"]
                
                f.write(f"**Found {len(self.duplications)} potential duplication patterns:**\n")
                f.write(f"- ğŸ”´ High severity: {len(high_duplications)}\n")
                f.write(f"- ğŸŸ¡ Medium severity: {len(medium_duplications)}\n\n")
                
                if high_duplications:
                    f.write("### ğŸ”´ High Priority Duplications\n\n")
                    for dup in high_duplications:
                        f.write(f"#### Pattern: `{dup.pattern}`\n")
                        f.write(f"**Files involved:** {', '.join(dup.files)}\n")
                        f.write(f"**Methods ({len(dup.methods)}):** {', '.join(dup.methods[:5])}")
                        if len(dup.methods) > 5:
                            f.write(f" ... and {len(dup.methods) - 5} more")
                        f.write("\n")
                        f.write(f"**Optimization:** {dup.optimization_potential}\n\n")
                
                if medium_duplications:
                    f.write("### ğŸŸ¡ Medium Priority Duplications\n\n")
                    for dup in medium_duplications:
                        f.write(f"#### Pattern: `{dup.pattern}`\n")
                        f.write(f"**Impact:** {len(dup.methods)} methods in {len(dup.files)} files\n")
                        f.write(f"**Optimization:** {dup.optimization_potential}\n\n")
            else:
                f.write("âœ… No significant duplication patterns found!\n\n")
            
            # ĞĞ½Ğ°Ğ»Ğ¸Ğ· ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸
            f.write("## ğŸ“Š Complexity Analysis\n\n")
            if self.complexity_issues:
                f.write(f"**Found {len(self.complexity_issues)} complexity issues:**\n\n")
                
                by_type = defaultdict(list)
                for issue in self.complexity_issues:
                    by_type[issue.issue_type].append(issue)
                
                for issue_type, issues in by_type.items():
                    f.write(f"### {issue_type.replace('_', ' ').title()}\n\n")
                    for issue in issues:
                        f.write(f"**{issue.component}**\n")
                        f.write(f"- {issue.description}\n")
                        f.write(f"- Suggestion: {issue.optimization_suggestion}\n\n")
            else:
                f.write("âœ… No significant complexity issues found!\n\n")
            
            # Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸
            f.write("## ğŸ’¡ Optimization Recommendations\n\n")
            
            # ĞÑ†ĞµĞ½ĞºĞ° impact vs effort
            total_issues = len(self.duplications) + len(self.complexity_issues)
            if total_issues == 0:
                f.write("### ğŸ‰ TestKit is well-designed!\n")
                f.write("No significant duplication or complexity issues found.\n")
                f.write("Current architecture appears optimal.\n\n")
            else:
                high_impact = len([d for d in self.duplications if d.severity == "high"])
                if high_impact > 0:
                    f.write("### ğŸ”¥ High Impact Optimizations\n")
                    f.write(f"**{high_impact} high-priority duplications** found.\n")
                    f.write("**Impact:** Reduced maintenance, clearer API\n")
                    f.write("**Effort:** Medium (refactoring required)\n")
                    f.write("**Recommendation:** Address these first\n\n")
                else:
                    f.write("### âœ… Low Impact Optimizations Only\n")
                    f.write("Most issues found are low-priority.\n")
                    f.write("**Recommendation:** Current design is good, minor tweaks only\n\n")
            
            # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²ÑŒÑ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹
            f.write("## ğŸ“ˆ Architecture Health Metrics\n\n")
            
            total_methods = sum(len(c['methods']) for c in self.index_data['components'])
            avg_methods_per_component = total_methods / len(self.index_data['components'])
            
            f.write(f"- **Average methods per component:** {avg_methods_per_component:.1f}\n")
            f.write(f"- **Total duplication patterns:** {len(self.duplications)}\n")
            f.write(f"- **Complexity issues:** {len(self.complexity_issues)}\n")
            
            # ĞÑ†ĞµĞ½ĞºĞ° Ğ¾Ğ±Ñ‰ĞµĞ³Ğ¾ Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²ÑŒÑ
            health_score = 100
            health_score -= len([d for d in self.duplications if d.severity == "high"]) * 10
            health_score -= len([d for d in self.duplications if d.severity == "medium"]) * 5
            health_score -= len(self.complexity_issues) * 3
            
            f.write(f"- **Architecture Health Score:** {max(0, health_score)}/100\n\n")
            
            if health_score >= 85:
                f.write("ğŸŸ¢ **Excellent architecture** - minimal issues\n")
            elif health_score >= 70:
                f.write("ğŸŸ¡ **Good architecture** - some optimization opportunities\n") 
            else:
                f.write("ğŸ”´ **Needs optimization** - significant issues found\n")
        
        print(f"ğŸ“‹ Generated duplication analysis: {output_path}")
        return health_score

def main():
    analyzer = TestKitAnalyzer("ClubDoorman.Test/TestKit/index.json")
    
    print("ğŸ” Loading TestKit index...")
    analyzer.load_index()
    
    print("ğŸ” Analyzing method name patterns...")
    analyzer.analyze_method_name_patterns()
    
    print("ğŸ“Š Analyzing component complexity...")
    analyzer.analyze_component_complexity()
    
    print("ğŸ·ï¸ Analyzing tag overlaps...")
    analyzer.analyze_tag_overlap()
    
    print("ğŸ“ Generating report...")
    health_score = analyzer.generate_report()
    
    print(f"\nâœ… Analysis complete!")
    print(f"ğŸ¥ Architecture Health Score: {health_score}/100")
    print(f"ğŸ” Found {len(analyzer.duplications)} duplication patterns")
    print(f"ğŸ“Š Found {len(analyzer.complexity_issues)} complexity issues")

if __name__ == "__main__":
    main()